<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Sign Language Datasets Survey – index</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
<h1 id="sign-language-recognition-datasets">Sign Language Recognition Datasets</h1>
<!--- TODO
CUNY details -> its a mocap dataset, worth including?

LIBRAS:

diccionario: http://www.acessibilidadebrasil.org.br/libras_3/

A fully automatic method for recognizing hand configurations of Brazilian sign language
http://www.scielo.br/scielo.php?script=sci_arttext&pid=S2446-47402017000100078
2017, Cicero Ferreira Fernandes Costa Filho, Robson Silva de Souza, Jonilson Roque dos Santos, Bárbara Lobato dos Santos, Marly Guimarães Fernandes Costa

Fingerspelling Recognition with Support Vector Machines and Hidden Conditional Random Fields: A comparison with Neural Networks and Hidden Markov Models
https://www.researchgate.net/publication/265096760_Fingerspelling_Recognition_with_Support_Vector_Machines_and_Hidden_Conditional_Random_Fields_A_comparison_with_Neural_Networks_and_Hidden_Markov_Models

An Experiment on Handshape Sign Recognition using Adaptive e Technology: Preliminary Results
http://www.gpec.ucdb.br/pistori/publicacoes/pistori_sbia2004.pdf

Recognizing Static Signs from the Brazilian Sign  Language: Comparing Large-Margin Decision Directed Acyclic Graphs, Voting Support Vector Machines and Artificial Neural Networks
https://arxiv.org/pdf/1210.7461.pdf
2011, César Roberto de Souza, Ednaldo Brigante Pizzolato, Mauro dos Santos Anjo

Recognizing the Brazilian Signs Language Alphabet with Neural Networks over Visual 3D Data Sensor
https://link.springer.com/chapter/10.1007/978-3-319-12027-0_51
2014, Gabriel de Souza Pereira Moreira et al

Reconhecimento do alfabeto de Libras usando sensor Kinect e marcadores visuais
http://bdm.unb.br/bitstream/10483/15173/1/2014_GiordanoBrunoDeMeloGois_tcc.pdf
2014, Giordano Bruno de Melo Gois (tesis)

Brazilian Sign Language Recognition Using Kinect
https://link.springer.com/chapter/10.1007%2F978-3-319-48881-3_27
2016, José Elías Yauri Vidalón y José Mario De Martino

Recognition of Static Gestures applied to Brazilian Sign Language (Libras)
https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7314578
2015, Igor Bastos, Michele F. Angelo y Angelo C. Loula

LATER:
Websites for greek, german, polish 101?
write cooper for details on german/greek/british datasets
add http://sun.aei.polsl.pl/~mkawulok/gestures/ db of handshapes
-->

<h2 id="sign-language-datasets">Sign language datasets</h2>
<h3 id="comparison">Comparison</h3>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">id</th>
<th style="text-align: center;">Name</th>
<th style="text-align: center;">Country</th>
<th style="text-align: center;">Classes</th>
<th style="text-align: center;">Subjects</th>
<th style="text-align: center;">Samples</th>
<th style="text-align: center;">Data</th>
<th style="text-align: center;">Language level</th>
<th style="text-align: center;">Type</th>
<th style="text-align: center;">Annotations</th>
<th style="text-align: center;">Availability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">DGS Kinect 40</td>
<td style="text-align: center;">Germany</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">15</td>
<td style="text-align: center;">3000</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">Videos, multiple angles</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Contact Author</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">RWTH-PHOENIX-Weather</td>
<td style="text-align: center;">Germany</td>
<td style="text-align: center;">1200</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;">45760</td>
<td style="text-align: center;">52gb</td>
<td style="text-align: center;">Sentence</td>
<td style="text-align: center;">Videos</td>
<td style="text-align: center;">Face, hand, end/start (unfinished)</td>
<td style="text-align: center;">Publicly Available</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">SIGNUM</td>
<td style="text-align: center;">Germany</td>
<td style="text-align: center;">450</td>
<td style="text-align: center;">25</td>
<td style="text-align: center;">33210</td>
<td style="text-align: center;">920gb</td>
<td style="text-align: center;">Sentence</td>
<td style="text-align: center;">Videos</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Publicly Available, 1TB, contact author to obtain hard drive</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">GSL 20</td>
<td style="text-align: center;">Greek</td>
<td style="text-align: center;">20</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">~840</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Contact Author</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">Boston ASL LVD</td>
<td style="text-align: center;">USA</td>
<td style="text-align: center;">3300+</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">9800</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">Videos, multiple angles</td>
<td style="text-align: center;">hand,end/start</td>
<td style="text-align: center;">Publicly Available</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">PSL Kinect 30</td>
<td style="text-align: center;">Poland</td>
<td style="text-align: center;">30</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">30×10=300</td>
<td style="text-align: center;">~1.2gb</td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">Videos, depth from Kinect camera</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Publicly Available</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">PSL ToF 84</td>
<td style="text-align: center;">Poland</td>
<td style="text-align: center;">84</td>
<td style="text-align: center;">1</td>
<td style="text-align: center;">84×20=1680</td>
<td style="text-align: center;">~33gb</td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">Videos, ToF camera</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Publicly Available</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">PSL 101</td>
<td style="text-align: center;">Poland</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Contact Author</td>
</tr>
<tr class="odd">
<td style="text-align: center;">9</td>
<td style="text-align: center;">LSA64</td>
<td style="text-align: center;">Argentina</td>
<td style="text-align: center;">64</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">3200</td>
<td style="text-align: center;">20gb</td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">Videos(rgb)</td>
<td style="text-align: center;">Hands and Head position</td>
<td style="text-align: center;">Publicly Available</td>
</tr>
<tr class="even">
<td style="text-align: center;">10</td>
<td style="text-align: center;">BosphorusSign</td>
<td style="text-align: center;">Turkey</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Non available</td>
</tr>
<tr class="odd">
<td style="text-align: center;">11</td>
<td style="text-align: center;">MSR Gesture 3D</td>
<td style="text-align: center;">USA</td>
<td style="text-align: center;">12</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">336</td>
<td style="text-align: center;">28mb</td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">Videos (depth)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Publicly Available</td>
</tr>
<tr class="even">
<td style="text-align: center;">12</td>
<td style="text-align: center;">DEVISIGN-G</td>
<td style="text-align: center;">China</td>
<td style="text-align: center;">36 (letters/numbers)</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">432</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">videos (rgb)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Contact author</td>
</tr>
<tr class="odd">
<td style="text-align: center;">13</td>
<td style="text-align: center;">DEVISIGN-D</td>
<td style="text-align: center;">China</td>
<td style="text-align: center;">500</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">6000</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">videos (rgb)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Contact author</td>
</tr>
<tr class="even">
<td style="text-align: center;">14</td>
<td style="text-align: center;">DEVISIGN-L</td>
<td style="text-align: center;">China</td>
<td style="text-align: center;">2000</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">24000</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">videos (rgb)</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Contact author</td>
</tr>
<tr class="odd">
<td style="text-align: center;">15</td>
<td style="text-align: center;">IIITA -ROBITA</td>
<td style="text-align: center;">India</td>
<td style="text-align: center;">23</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">284mb</td>
<td style="text-align: center;">Word</td>
<td style="text-align: center;">videos (rgb) 320x240</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Contact author</td>
</tr>
<tr class="even">
<td style="text-align: center;">16</td>
<td style="text-align: center;">Purdue ASL</td>
<td style="text-align: center;">USA</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">14 (only 5 available)</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">Word/sentence</td>
<td style="text-align: center;">Videos, RGB</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">Request DVDs/HD</td>
</tr>
<tr class="odd">
<td style="text-align: center;">17</td>
<td style="text-align: center;">CUNY ASL</td>
<td style="text-align: center;">USA</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">8</td>
<td style="text-align: center;">~33000 glosses,</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">Sentence</td>
<td style="text-align: center;">videos (rgb), mocap data</td>
<td style="text-align: center;">Signstream</td>
<td style="text-align: center;">Unknown</td>
</tr>
<tr class="even">
<td style="text-align: center;">18</td>
<td style="text-align: center;">SignsWorld Atlas</td>
<td style="text-align: center;">Arabia</td>
<td style="text-align: center;">multiple types</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">Handshape, Words, Sentences</td>
<td style="text-align: center;">Images, Videos, RGB</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">Unknown</td>
</tr>
</tbody>
</table>
<!--6   | CUNY                |USA       |      |      |           |      |Word        |                                  |            ||-->

<h3 id="dataset-information-and-related-papers">Dataset information and related papers</h3>
<ol>
<li>DGS Kinect 40 - German Sign Language (no website)
<ol>
<li><a href="http://jmlr.csail.mit.edu/papers/volume13/cooper12a/cooper12a.pdf">Sign Language Recognition using Sub-Units</a>, 2012, Cooper et al.</li>
<li><a href="https://pdfs.semanticscholar.org/e8a1/84e76d6476ecc27857b1c1b280af5628d0ae.pdf">Sign Language Recognition using Sequential Pattern Trees</a> 2012, Ong et al.</li>
<li><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Ong_Sign_Spotting_using_2014_CVPR_paper.pdf">Sign Spotting using Hierarchical Sequential Patterns with Temporal Intervals</a> 2014, Ong et al.</li>
</ol></li>
<li><a href="http://www-i6.informatik.rwth-aachen.de/~forster/database-rwth-phoenix.php">RWTH-PHOENIX v1 - German Sign Language</a> <a href="https://www-i6.informatik.rwth-aachen.de/~koller/RWTH-PHOENIX/">RWTH-PHOENIX v2</a>
<ol>
<li><a href="http://www-i6.informatik.rwth-aachen.de/publications/download/773/forster-lrec-2012.pdf">Dataset paper</a> 2012, Forster et al.</li>
<li><a href="http://www.lrec-conf.org/proceedings/lrec2014/pdf/585_Paper.pdf">Dataset extensions paper</a> 2014, Forster et al</li>
<li><a href="http://www.sciencedirect.com/science/article/pii/S1077314215002088">Continuous sign language recognition: Towards large vocabulary statistical recognition systems handling multiple signers</a> 2015, Koller et al. 4.<a href="http://www-i6.informatik.rwth-aachen.de/publications/download/852/Koller-FG-2013.pdf">May the force be with you: Force-aligned signwriting for automatic subunit annotation of corpora</a> 2013, Koller et al.</li>
<li><a href="http://epubs.surrey.ac.uk/812319/">Deep Sign: Hybrid CNN-HMM for Continuous Sign Language Recognition</a></li>
<li></li>
</ol></li>
<li><a href="http://www.phonetik.uni-muenchen.de/forschung/Bas/SIGNUM/">SIGNUM - German Sign Language</a>
<ol>
<li><a href="http://www.sciencedirect.com/science/article/pii/S1077314215002088">Continuous sign language recognition: Towards large vocabulary statistical recognition systems handling multiple signers</a> 2015, Koller et al.</li>
</ol></li>
<li>Greek Sign Language (no website)
<ol>
<li><a href="http://jmlr.csail.mit.edu/papers/volume13/cooper12a/cooper12a.pdf">Sign Language Recognition using Sub-Units</a>, 2012, Cooper et al.</li>
<li><a href="https://pdfs.semanticscholar.org/e8a1/84e76d6476ecc27857b1c1b280af5628d0ae.pdf">Sign Language Recognition using Sequential Pattern Trees</a> 2012, Ong et al.</li>
<li><a href="http://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Ong_Sign_Spotting_using_2014_CVPR_paper.pdf">Sign Spotting using Hierarchical Sequential Patterns with Temporal Intervals</a> 2014, Ong et al.</li>
</ol></li>
<li><a href="http://www.bu.edu/av/asllrp/dai-asllvd.html">Boston ASLLVD - American Sign Language</a>
<ul>
<li><a href="http://www.bu.edu/asllrp/1826-CVPR_2011.pdf">Exploiting Phonological Constraints for Handshape Inference in ASL Video</a> 2011, Thangali et al.</li>
<li><a href="http://www.lrec-conf.org/proceedings/lrec2014/pdf/1138_Paper.pdf">A New Framework for Sign Language Recognition based on 3D Handshape Identification and Linguistic Modeling</a> 2014 - Dilsizian - 84% accuracy</li>
</ul></li>
<li><a href="http://vision.kia.prz.edu.pl/dynamickinect.php">PSL Kinect 30 - Polish Sign Language</a>
<ol>
<li><a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=6577826&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6577826">Polish sign language words recognition with Kinect </a> 2013, Oszust et al.</li>
<li><a href="http://link.springer.com/chapter/10.1007%2F978-3-319-08491-6_7">Some Approaches to Recognition of Sign Language Dynamic Expressions with Kinect </a> 2014, Oszust et al.</li>
<li><a href="http://cdn.intechopen.com/pdfs-wm/48352.pdf">Recognition of Hand Gestures Observed by Depth Cameras</a> 2015, Kapuscinski et al.</li>
</ol></li>
<li><a href="http://vision.kia.prz.edu.pl/dynamictof.php">PSL ToF 84 - Polish Sign Language</a>
<ol>
<li><a href="http://ieeexplore.ieee.org/xpl/login.jsp?tp=&amp;arnumber=6577826&amp;url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D6577826">Polish sign language words recognition with Kinect</a> 2013, Oszust et al.</li>
<li><a href="http://cdn.intechopen.com/pdfs-wm/48352.pdf">Recognition of Hand Gestures Observed by Depth Cameras</a> 2015, Kapuscinski et al.</li>
</ol></li>
<li>PSL 101 - Polish Sign Language (no website)
<ol>
<li><a href="http://link.springer.com/chapter/10.1007%2F978-3-642-33185-5_35#page-2">Modelling and Recognition of Signed Expressions Using Subunits Obtained by Data–Driven Approach</a> 2012, Oszust et al.</li>
</ol></li>
<li><a href="http://facundoq.github.io/unlp/lsa64/index.html">LSA64 Argentinian Sign Language</a>
<ol>
<li><a href="http://sedici.unlp.edu.ar/handle/10915/56764">LSA64: an Argentinian Sign Language Dataset</a></li>
<li><a href="https://link.springer.com/chapter/10.1007/978-3-319-47955-2_28">Sign Languague Recognition Without Frame-Sequencing Constraints: A Proof of Concept on the Argentinian Sign Language</a></li>
<li><a href="http://sedici.unlp.edu.ar/handle/10915/62945">Dynamic Gesture Recognition and its Application to Sign Language</a> 2017, Ronchetti</li>
<li><a href="https://www.researchgate.net/profile/Kosmas_Dimitropoulos/publication/325011717_Sign_Language_Recognition_based_on_Hand_and_Body_Skeletal_Data/links/5af160e3a6fdcc24364b1024/Sign-Language-Recognition-based-on-Hand-and-Body-Skeletal-Data.pdf">SIGN LANGUAGE RECOGNITION BASED ON HAND AND BODY SKELETAL DATA</a> 2017, Konstantinidis et al.</li>
<li><a href="https://link.springer.com/chapter/10.1007/978-981-10-7566-7_63">Real-Time Sign Language Gesture (Word) Recognition from Video Sequences Using CNN and RNN</a> 2018, Masood et al.</li>
</ol></li>
<li><a href="https://www.cmpe.boun.edu.tr/pilab/BosphorusSign/home_en.html">Turkish sign language dataset</a></li>
<li><a href="https://www.microsoft.com/en-us/research/people/zliu/?from=http%3A%2F%2Fresearch.microsoft.com%2Fen-us%2Fum%2Fpeople%2Fzliu%2Factionrecorsrc%2F">MSR Gesture 3D - ASL </a> <a href="https://www.uow.edu.au/~wanqing/#Datasets">Download site</a>
<ol>
<li><a href="https://link.springer.com/article/10.1007/s11042-016-3284-7">Action Recognition from Depth Sequences Using Weighted Fusion of 2D and 3D Auto-Correlation of Gradients Features</a> 2016, Chen et al</li>
</ol></li>
<li><a href="http://vipl.ict.ac.cn/homepage/ksl/data.html#page3">DEVISIGN G</a></li>
<li><a href="http://vipl.ict.ac.cn/homepage/ksl/data.html#page3">DEVISIGN D</a></li>
<li><a href="http://vipl.ict.ac.cn/homepage/ksl/data.html#page3">DEVISIGN L</a></li>
<li>[IIITA -ROBITA Indian Sign Language Gesture Database ] (<a href="https://robita.iiita.ac.in/dataset.php" class="uri">https://robita.iiita.ac.in/dataset.php</a>)
<ol>
<li><a href="https://ieeexplore.ieee.org/document/5640434/">Recognizing &amp; Interpreting Indian Sign Language Gesture for Human Robot Interaction</a> 2010, Nandy et al.</li>
<li><a href="https://pdfs.semanticscholar.org/fa4d/a909eeebc9a923e29502e3eb2dd6c40ca083.pdf"> Recognition of Isolated Indian Sign Language gesture in Real Time </a> 2010, Nandy et al.</li>
</ol></li>
</ol>
<!--9. [CUNY](http://eniac.cs.qc.cuny.edu/matt/pubs/lu-huenerfauth-2012-lrec.pdf)-->

<ol start="16">
<li><a href="http://www2.ece.ohio-state.edu/~aleix/ASLdatabase.htm">Purdue ASL Dataset</a></li>
<li><a href="latlab.cs.qc.cuny.edu/corpus">CUNY ASL Dataset for Animation</a>
<ol>
<li><a href="https://www.sciencedirect.com/science/article/pii/S0885230813000879">Collecting and evaluating the CUNY ASL corpus for research on American Sign Language animation</a></li>
</ol></li>
<li><a href="https://www.sciencedirect.com/science/article/pii/S1319157814000548">SignsWorld Atlas; a benchmark Arabic Sign Language database</a></li>
</ol>
<h2 id="handshapehand-posture-datasets-not-all-are-for-sign-language">Handshape/hand posture datasets (not all are for sign language)</h2>
<h3 id="comparison-1">Comparison</h3>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">id</th>
<th style="text-align: center;">Name</th>
<th style="text-align: center;">Country</th>
<th style="text-align: center;">Classes</th>
<th style="text-align: center;">Subjects</th>
<th style="text-align: center;">Samples</th>
<th style="text-align: center;">Data</th>
<th style="text-align: center;">Type</th>
<th style="text-align: center;">Availability</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">1</td>
<td style="text-align: center;">ASL Fingerspelling A</td>
<td style="text-align: center;">USA</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">5</td>
<td style="text-align: center;">131000</td>
<td style="text-align: center;">2.1gb</td>
<td style="text-align: center;">images (depth+rgb)</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="even">
<td style="text-align: center;">2</td>
<td style="text-align: center;">ASL Fingerspelling B</td>
<td style="text-align: center;">USA</td>
<td style="text-align: center;">24</td>
<td style="text-align: center;">9</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">317mb</td>
<td style="text-align: center;">images (depth)</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="odd">
<td style="text-align: center;">3</td>
<td style="text-align: center;">LSA16 handshapes</td>
<td style="text-align: center;">Argentina</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">800</td>
<td style="text-align: center;">7mb</td>
<td style="text-align: center;">images (rgb)</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="even">
<td style="text-align: center;">4</td>
<td style="text-align: center;">PSL Fingerspelling ToF</td>
<td style="text-align: center;">Poland</td>
<td style="text-align: center;">16</td>
<td style="text-align: center;">3</td>
<td style="text-align: center;">960</td>
<td style="text-align: center;">~290mb</td>
<td style="text-align: center;">3D point cloud</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="odd">
<td style="text-align: center;">5</td>
<td style="text-align: center;">ISL</td>
<td style="text-align: center;">Irish</td>
<td style="text-align: center;">23 static + 3 dynamic</td>
<td style="text-align: center;">6</td>
<td style="text-align: center;">58114 frames / 468 videos</td>
<td style="text-align: center;">170mb</td>
<td style="text-align: center;">segmented images</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="even">
<td style="text-align: center;">6</td>
<td style="text-align: center;">RWTH-PHOENIX-Weather Handshapes</td>
<td style="text-align: center;">German</td>
<td style="text-align: center;">60</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">3359 labelled + 17gb unlabeled</td>
<td style="text-align: center;">+ 17gb</td>
<td style="text-align: center;">Hand Images (rgb)</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="odd">
<td style="text-align: center;">7</td>
<td style="text-align: center;">Japanese Fingerspelling Dataset</td>
<td style="text-align: center;">Japan</td>
<td style="text-align: center;">41</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">8055</td>
<td style="text-align: center;">segmented images (rgb), 32x32</td>
<td style="text-align: center;">4.5mb</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="even">
<td style="text-align: center;">8</td>
<td style="text-align: center;">NUS hand posture dataset I</td>
<td style="text-align: center;">Singapore</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">240</td>
<td style="text-align: center;">images (rgb), 160x120</td>
<td style="text-align: center;">3mb</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="odd">
<td style="text-align: center;">9</td>
<td style="text-align: center;">NUS hand posture dataset II</td>
<td style="text-align: center;">Singapore</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">40</td>
<td style="text-align: center;">2000</td>
<td style="text-align: center;">images (rgb) 160x120</td>
<td style="text-align: center;">73mb</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="even">
<td style="text-align: center;">10</td>
<td style="text-align: center;">CIARP</td>
<td style="text-align: center;">-</td>
<td style="text-align: center;">10</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">6000</td>
<td style="text-align: center;">images (rgb) 38x38</td>
<td style="text-align: center;">11mb</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="odd">
<td style="text-align: center;">11</td>
<td style="text-align: center;">RTWH Fingerspelling dataset</td>
<td style="text-align: center;">Germany</td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
<td style="text-align: center;"></td>
</tr>
<tr class="even">
<td style="text-align: center;">12</td>
<td style="text-align: center;">Indian Kinect</td>
<td style="text-align: center;">India</td>
<td style="text-align: center;">140</td>
<td style="text-align: center;">18</td>
<td style="text-align: center;">5041</td>
<td style="text-align: center;">images (rgb+depth) 640x480</td>
<td style="text-align: center;">2gb</td>
<td style="text-align: center;">Free download</td>
</tr>
<tr class="odd">
<td style="text-align: center;">13</td>
<td style="text-align: center;">Arabic Alphabets Sign Language Dataset (ArASL)</td>
<td style="text-align: center;">Arabia</td>
<td style="text-align: center;">32</td>
<td style="text-align: center;">?</td>
<td style="text-align: center;">54,049</td>
<td style="text-align: center;">images (rgb)</td>
<td style="text-align: center;">64mb</td>
<td style="text-align: center;">Free download</td>
</tr>
</tbody>
</table>
<h3 id="dataset-information-and-related-papers-1">Dataset information and related papers</h3>
<ol>
<li><p><a href="http://empslocal.ex.ac.uk/people/staff/np331/index.php?section=FingerSpellingDataset">ASL Fingerspelling A</a></p>
<ol>
<li><a href="http://personal.ee.surrey.ac.uk/Personal/N.Pugeault/publications/PugeaultBowden2011b.pdf">Spelling It Out: Real-Time ASL Fingerspelling Recognition</a>. 2011, Pugeault et al.</li>
</ol></li>
<li><p><a href="http://empslocal.ex.ac.uk/people/staff/np331/index.php?section=FingerSpellingDataset">ASL Fingerspelling B</a></p>
<ol>
<li><a href="http://personal.ee.surrey.ac.uk/Personal/N.Pugeault/publications/PugeaultBowden2011b.pdf">Spelling It Out: Real-Time ASL Fingerspelling Recognition</a>. 2011, Pugeault et al.</li>
<li><a href="http://cdn.intechopen.com/pdfs-wm/48352.pdf">Recognition of Hand Gestures Observed by Depth Cameras</a>. 2015, Kapuscinski et al.</li>
</ol></li>
<li><p><a href="http://vision.kia.prz.edu.pl/statictof.php">PSL Fingerspelling ToF</a></p>
<ol>
<li><a href="http://cdn.intechopen.com/pdfs-wm/48352.pdf">Recognition of Hand Gestures Observed by Depth Cameras</a>. 2015, Kapuscinski et al.</li>
</ol></li>
<li><p><a href="http://facundoq.github.io/unlp/lsa16/index.html">LSA16 handshapes</a></p>
<ol>
<li><a href="http://journal.info.unlp.edu.ar/wp-content/uploads/2015/10/JCST-42-Paper-1.pdf">Handshape recognition for Argentinian Sign Language using ProbSom</a>. 2016, Ronchetti et al.</li>
<li><a href="http://sedici.unlp.edu.ar/handle/10915/63481">A Study of Convolutional Architectures for Handshape Recognition applied to Sign Language</a> 2017, Quiroga et al.</li>
</ol></li>
<li><p><a href="https://github.com/marlondcu/ISL">ISL Irish Sign Language Letters</a>.</p>
<ol>
<li><a href="http://doras.dcu.ie/21882/1/IMVIP_short_cr.pdf">A Dataset for Irish Sign Language Recognition</a> 2017, Oliveira et al.</li>
<li><a href="http://doras.dcu.ie/22132/1/Houssem_-_IVCNZ_2017.pdf">A comparison between end-to-end approaches and feature extraction based approaches for Sign Language recognition</a> 2017, Oliveira et al.</li>
</ol></li>
<li><p><a href="https://www-i6.informatik.rwth-aachen.de/~koller/1miohands-data/">RWTH-PHOENIX-Weather 2014 MS Handshapes</a></p>
<ol>
<li><a href="https://www-i6.informatik.rwth-aachen.de/publications/download/1000/Koller-CVPR-2016.pdf"> Deep Hand: How to Train a CNN on 1 Million Hand Images When Your Data Is Continuous and Weakly Labelled </a> 2017, Koller et al.</li>
</ol></li>
<li><p><a href="http://home.agh.edu.pl/~bkw/research/data/mva/jsl.zip">Japanese Sign Language Dataset</a></p>
<ol>
<li><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7986796">Recognition of JSL Finger Spelling Using Convolutional Neural Networks</a> 2017, Hosoe, Sako and Kwolek</li>
<li><a href="https://link.springer.com/chapter/10.1007/978-3-319-70353-4_20">Learning Siamese Features for Finger Spelling Recognition</a> 2017, Sako and Kwolek</li>
</ol></li>
<li><p><a href="https://www.ece.nus.edu.sg/stfpage/elepv/NUS-HandSet/">NUS hand posture dataset I</a></p>
<ol>
<li><a href="http://vadakkepat.com/web/images/stories/pubs/ijhr-2010.pdf">Hand posture and face recognition using a Fuzzy-Rough Approach</a> 2010, Pramod Kumar P, Prahlad Vadakkepat, and Loh Ai Poh</li>
<li><a href="https://www.researchgate.net/publication/322915265_Hand_Posture_Recognition_Using_Convolutional_Neural_Network">Hand Posture Recognition Using Convolutional Neural Network</a></li>
</ol></li>
<li><p><a href="https://www.ece.nus.edu.sg/stfpage/elepv/NUS-HandSet/">NUS hand posture dataset II</a> 1.<a href="http://link.springer.com/article/10.1007%2Fs11263-012-0560-5?LI=true">Attention Based Detection and Recognition of Hand Postures Against Complex Backgrounds</a> 2013, Pisharady et al</p></li>
<li><p><a href="http://home.agh.edu.pl/~bkw/code/ciarp2017/">CIARP 2017</a></p>
<ol>
<li><a href="https://link.springer.com/chapter/10.1007/978-3-319-75193-1_53">Hand Posture Recognition Using Convolutional Neural Network</a></li>
</ol></li>
<li><p><a href="http://www-i6.informatik.rwth-aachen.de/aslr/fingerspelling.php">RTWH Fingerspelling dataset</a></p></li>
<li><p><a href="https://www-i6.informatik.rwth-aachen.de/publications/download/29/Dreuw-ECCV-SMVP-2006.pdf"> Modeling Image Variability in Appearance-Based Gesture Recognition. In ECCV Workshop on Statistical Methods in Multi-Image and Video Processing</a></p></li>
<li><p><a href="https://www.ias.ac.in/article/fulltext/sadh/041/02/0161-0182">Indian Kinect</a> <a href="https://github.com/zafar142007/Gesture-Recognition-for-Indian-Sign-Language-using-Kinect">github</a></p></li>
<li><p><a href="https://www.ias.ac.in/article/fulltext/sadh/041/02/0161-0182">Nearest neighbour classification of Indian sign language gestures using kinect camera</a> 2016, Ansari and Harit</p></li>
<li><p><a href="https://data.mendeley.com/datasets/y7pckrw6z2/1">Arabic Alphabets Sign Language Dataset (ArASL)</a></p></li>
<li><p><a href="https://www.researchgate.net/publication/285755274_Arabic_Alphabet_and_Numbers_Sign_Language_Recognition">Arabic Alphabet and Numbers Sign Language Recognition</a></p></li>
</ol>
<h2 id="other-info">Other info</h2>
<p>Kevin Murphy mantains a similar list for <a href="http://www.cs.ubc.ca/~murphyk/videodata.html">Action Recognition Datasets</a>.</p>
<p>Other similar websites with sign language dataset compilations are:</p>
<ul>
<li><a href="http://ww1.chalearn.org/resou/databases">Chalearn dataset list</a></li>
<li><a href="https://www-i6.informatik.rwth-aachen.de/web/Software/Databases/Signlanguage/?db=rwth-boston-104">RWTH datasets list</a></li>
</ul>
<p>Papers that cite datasets that are unavailable:</p>
<ul>
<li>480 signs, Indian Sign Language
<ul>
<li><a href="https://pdfs.semanticscholar.org/37f8/0b0bf92dae99fc66fea90973e3b3e1b42e86.pdf">Segment, Track, Extract, Recognize and Convert Sign Language Videos to Voice/Text</a> 2012, Kishore and Kumar</li>
<li><a href="https://www.sciencedirect.com/science/article/pii/S2090447917300217">Selfie video based continuous Indian sign language recognition system</a> 2017, Rao and Kishore</li>
</ul></li>
<li>10 signs, indian sign language
<ul>
<li><a href="https://ieeexplore.ieee.org/document/5640434/?part=1">Recognizing &amp; interpreting Indian Sign Language gesture for Human Robot Interaction</a> 2010, Nandy et al.</li>
</ul></li>
<li>24 static handshapes, Indian Sign Language
<ul>
<li><a href="https://arxiv.org/pdf/1306.1301.pdf">Recognition of Indian Sign Language in Live Video</a> 2013, Singha and Das</li>
</ul></li>
</ul>
<p>Hand movement datasets (movement only):</p>
<ol>
<li><a href="https://archive.ics.uci.edu/ml/datasets/Libras+Movement">LIBRAS hand movement</a>
<ol>
<li><a href="https://ieeexplore.ieee.org/document/5178917/">Hand Movement Recognition for Brazilian Sign Language: A Study Using Distance-Based Neural Networks.</a></li>
</ol></li>
</ol>
<h2 id="non-manual-features">Non-manual features</h2>
<ol>
<li>QLIBRAS
<ol>
<li><a href="https://pdfs.semanticscholar.org/919a/1e2bea81a7dc52dfa20fe530cf75a8f307da.pdf">QLIBRAS: A novel database for grammatical facial expressions in Brazilian Sign Language</a></li>
</ol></li>
</ol>
<h2 id="continuous-hand-pose">Continuous hand pose</h2>
<ol>
<li><a href="https://cims.nyu.edu/~tompson/NYU_Hand_Pose_Dataset.htm">NYU Hand pose dataset</a>
<ol>
<li><a href="https://cims.nyu.edu/~tompson/others/TOG_2014_paper_PREPRINT.pdf">Real-Time Continuous Pose Recovery of Human Hands Using Convolutional Networks</a></li>
</ol></li>
</ol>
</body>
</html>
